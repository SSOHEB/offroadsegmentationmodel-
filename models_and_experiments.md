# Models & Experiments Log

## Executive Summary
| Experiment | Model | Loss | Final IoU | Status |
| :--- | :--- | :--- | :--- | :--- |
| **EXP-1** | Custom UNet | CE + Class Weights | **57.2%** (TTA) | ‚úÖ Best |
| **EXP-2** | Custom UNet | Dice+CE + Scheduler | 0.4057 | ‚ùå Failed |
| **EXP-3** | ResNet34-UNet | CE (ImageNet pretrained) | 0.4500 | ‚ùå Lower |
| **EXP-4** | Custom UNet | CE (100 epochs) | 0.5107 | ‚ö†Ô∏è Oscillating |
| **EXP-5** | ResNet34-UNet | CE (Frozen Encoder) | TBD | üîÑ Next |

---

## Experiment 1: Baseline (BEST RESULT ‚úÖ)

### Configuration
| Parameter | Value |
| :--- | :--- |
| Model | Custom UNet (4 encoder, 4 decoder blocks) |
| Loss | `CrossEntropyLoss` with class weights |
| Optimizer | Adam (lr=0.001) |
| Epochs | 50 |
| Resolution | 256√ó256 |

### Results
-   **Final Val IoU**: **57.2%** (with TTA)
-   **Training Time**: ~1.5 hours
-   **Model File**: `checkpoints/best_model.pth`

---

## Experiment 2: Dice+CE Approach (FAILED ‚ùå)

### Hypothesis
> "Combining Dice Loss with CrossEntropy will directly optimize IoU."

### Results
| Metric | EXP-1 | EXP-2 |
| :--- | :--- | :--- |
| **Final Val IoU** | **57.2%** (TTA) | 0.4057 |
| **Convergence** | Smooth | Slow, oscillating |

### Lesson Learned
> **Simpler is better.** CE with class weighting outperformed the Dice+CE combo.

---

## Experiment 3: ResNet34 Backbone (FAILED ‚ùå)

### Hypothesis
> "Pretrained ResNet34 encoder will provide better features."

### Configuration
| Parameter | Value |
| :--- | :--- |
| Model | UNet with ResNet34 encoder (ImageNet) |
| Loss | CrossEntropyLoss (Weighted) |
| Optimizer | Adam (lr=0.0001) |
| Epochs | 50 |

### Results
-   **Final Val IoU**: 0.4500 (45%)
-   **Best Epoch**: 49 (0.4500)

### Why It Failed
1.  **ImageNet Normalization Mismatch**: Terrain images have different color distribution than natural images
2.  **Domain Gap**: ResNet learned cats/dogs, not terrain textures
3.  **Learning Rate Too Low**: 0.0001 was too conservative

---

## Experiment 4: UNet 100 Epochs (PARTIAL ‚ö†Ô∏è)

### Hypothesis
> "More epochs will improve the baseline UNet beyond 0.52."

### Configuration
| Parameter | Value |
| :--- | :--- |
| Model | Custom UNet |
| Loss | CrossEntropyLoss (Weighted) |
| Epochs | **100** (vs 50 in baseline) |
| LR | 0.001 |

### Results
-   **Best Val IoU**: 0.5107 (Epoch 94)
-   **Final Val IoU**: 0.4968 (Epoch 100)
-   **Training Time**: ~5 hours

### Training Progression
| Epoch | Val IoU | Notes |
| :--- | :--- | :--- |
| 10 | 0.28 | Starting |
| 25 | 0.36 | Climbing |
| 50 | 0.39 | Below baseline |
| 75 | 0.48 | Approaching |
| 90 | 0.50 | Near baseline |
| 94 | **0.51** | Best |
| 100 | 0.50 | Final |

### Analysis
-   Heavy oscillation throughout training
-   LR (0.001) too aggressive for later epochs
-   Scheduler didn't reduce LR effectively
-   Did NOT beat baseline (0.52)

---

## Experiment 5: Frozen Encoder (PLANNED üîÑ)

### Hypothesis
> "Freezing the pretrained ResNet encoder and only training the decoder will preserve ImageNet features while adapting to our domain."

### Configuration
| Parameter | Value |
| :--- | :--- |
| Model | UNet with ResNet34 encoder |
| Encoder | **FROZEN** (ImageNet weights fixed) |
| Decoder | Trainable |
| Loss | CrossEntropyLoss (Weighted) |
| LR | 0.001 (higher, since only decoder trains) |
| Epochs | 50 |

### Expected Benefit
-   ImageNet features preserved (no domain gap tuning)
-   Faster training (fewer parameters)
-   Decoder learns domain-specific patterns

---

## Techniques Summary

### ‚úÖ Worked
| Technique | Impact |
| :--- | :--- |
| **Class Weighting** | High ‚Äî rare classes detectable |
| **Offline Preprocessing** | High ‚Äî 95% I/O reduction |
| **GPU Migration** | High ‚Äî 34√ó speedup |

### ‚ùå Didn't Work
| Technique | Issue |
| :--- | :--- |
| **Dice+CE Loss** | Slower convergence |
| **Pretrained ResNet (full training)** | Domain gap hurt accuracy |
| **100 epochs** | Oscillation, no improvement |

---

## Files Produced

| File | Experiment | IoU |
| :--- | :--- | :--- |
| `best_model.pth` (local) | EXP-1 | **0.52** |
| `resnet_checkpoints/` | EXP-3 | 0.45 |
| `unet_100epoch_checkpoints/` | EXP-4 | 0.51 |
